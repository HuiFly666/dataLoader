import torch  
import torchaudio  
from torch.utils.data import Dataset  

# 自定义数据集  
class AudioDataset(Dataset):  
    def __init__(self, audio_files, labels):  
        self.audio_files = audio_files  
        self.labels = labels  # 使用目标标签  

    def __len__(self):  
        return len(self.audio_files)  

    def __getitem__(self, idx):  
        # 加载音频文件  
        waveform, sample_rate = torchaudio.load(self.audio_files[idx])  

        # pad_or_trim_waveform 函数假定已定义，需保证波形的长度  
        waveform = pad_or_trim_waveform(waveform, sample_rate * 12)  # 例如处理到12秒  
        # 提取梅尔频谱图  
        mel_specgram = torchaudio.transforms.MelSpectrogram(sample_rate)(waveform)  

        # 梅尔频谱图的标准化  
        mel_specgram_norm = (mel_specgram - mel_specgram.mean()) / mel_specgram.std()  
        
        # 调整为模型输入所需的格式  
        # 从 (channels, n_mels, time) 到 (batch_size, channels, height, width)  
        # 这里假设 mel_specgram_norm 是 (1, n_mels, time)，并添加 batch_size 维度  
        feature = mel_specgram_norm.unsqueeze(0)  # (1, 1, n_mels, time)  

        # 返回特征和标签  
        return feature, self.labels[idx]  

# 示例用法  
# 假设有音频文件路径和相应标签  
audio_files = ['path/to/audio1.wav', 'path/to/audio2.wav']  
labels = [0, 1]  # 对应每个音频的标签  

dataset = AudioDataset(audio_files, labels)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio

# 数据预处理
def load_audio(file_path):
    waveform, sample_rate = torchaudio.load(file_path)
    mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate)(waveform)
    return mel_spectrogram.log2()

# 定义CNN模型
class AudioCNN(nn.Module):  
    def __init__(self, n_feature):  
        super(AudioCNN, self).__init__()  
        # 假设输入样本的通道数为 1, 如果你的特征数量不同要根据需要调整  
        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3))  
        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))  
        self.pool = nn.MaxPool2d(2, 2)  
        
        # 计算 fc1 层的输入大小  
        # 假设输入图像的大小为 (n_feature, 输入宽度, 输入高度)  
        # 需要根据输入的维度调整 (假设为 125)  
        self.fc1_input_size = 64 * ((n_feature - 2) // 2) * ((n_feature - 2) // 2)  # 根据输入特征数来调整  
        self.fc1 = nn.Linear(self.fc1_input_size, 128)  
        self.fc2 = nn.Linear(128, 1)  # 二分类，若多类可用 softmax  

    def forward(self, x):  
        x = self.pool(F.relu(self.conv1(x)))  # Conv1 处理，跟随 Pooling  
        x = self.pool(F.relu(self.conv2(x)))  # Conv2 处理，跟随 Pooling  
        x = x.view(-1, self.fc1_input_size)  # 展平  
        x = F.relu(self.fc1(x))  # 全连接层1  
        x = torch.sigmoid(self.fc2(x))  # 全连接层2，二分类  
        return x  

# 创建模型
model = AudioCNN()

